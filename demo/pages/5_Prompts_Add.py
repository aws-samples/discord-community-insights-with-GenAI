import streamlit as st
import time, requests, json

domain_url = st.session_state.domain_url
api_key = st.session_state.api_key

def few_shot_callback(string):
    st.write



topic = st.text_input(
    "Enter TopicğŸ‘‡ (required)",
    placeholder="input topic name,like 'æ‹å–è¡Œ'",
)

prompt_rag = st.text_area(
    "Enter Prompt RagğŸ‘‡ (required)",
    placeholder="Prompt RAG, using to extract relavent information from raw data",
)

prompt_sentiment = st.text_area(
    "Enter Prompt SentimentğŸ‘‡ (required)",
    placeholder="Prompt Sentiment, using to analysis sentiment infromation from extracted data",
)

prompt_sentiment = st.text_area(
    "Enter SamplesğŸ‘‡ (optional)",
    placeholder="1. æ‹å–è¡Œå¤šé¦™ 2. æˆ‘æ‹åˆ°å¥½ä¸œè¥¿äº†"
)

if st.button('æäº¤'):
    if topic.strip() == "":
        st.write("Topic cannot be emptyï¼")

    if prompt_rag.strip() == "":
        st.write("Prompt RAG cannot be emptyï¼")

    if prompt_sentiment.strip() == "":
        st.write("Prompt sentiment cannot be emptyï¼")

    url = domain_url + "/prompts"

    headers = {
      'x-api-key': api_key,
      'Content-Type': 'application/json'
    }
    response = json.loads(requests.request("GET", url, headers=headers).text)

    payload = json.dumps({
      "topic": topic,
      "prompt_rag": prompt_rag,
      "prompt_sentiment": prompt_sentiment
    })
    headers = {
      'x-api-key': api_key,
      'Content-Type': 'application/json'
    }

    response = requests.request("POST", url, headers=headers, data=payload)

    st.success('Submit success!', icon="âœ…")

st.markdown("<font color="red">###æç¤ºè¯æ ·ä¾‹å¦‚ä¸‹ï¼Œå…¶ä¸­{context} , {relevant_info} å’Œ {topic} è¯·ä¸è¦åŠ¨</font>")
st.markdown("### Prompt RAG")
code = '''
You are an expert research assistant, tasked with identifying player sentiments regarding certain in-game items, neutral NPCs, and game market activities.

Here is a document you will analyze
<doc>
{context}
</doc>

Here is a task:
First, find the quotes from the document that are most relevant to {topic}, and then print them in numbered order. Quotes should be relatively short.
If there are no relevant quotes, write "No relevant quotes" instead.
please enclose your analysis results in xml tag <response>.

for example:
<response>
1. "æ‹å–è¡Œå¤šé¦™"
2. "æˆ‘æ‹åˆ°å¥½ä¸œè¥¿äº†"
3. "æ‹å–è¡Œå¤ªå·®åŠ²äº†"
4. "auction sucks"
5. "æ‹å–è¡Œæœ‰äººå‘åŒ…"
</response>

Skip the preamble, go straight into the answer.
'''
st.code(code, language='python')
st.markdown("### Prompt Sentiment")
code = '''
You are a chat message sentiment classifer

Here is a document you will classify the senetiment
<doc>
{relevant_info}
</doc>
please list all the content if it is relevant to {topic} and classify the sentiment of each content into [positive,neutral,negative]'
Please follow below requirements:
1. You will strictly be based on the document in <doc>.
2. please enclose your analysis results in xml tag <sentiment>.

for example:
<sentiment>
1. "æ‹å–è¡Œå¤šé¦™" [positive]
2. "æˆ‘æ‹åˆ°å¥½ä¸œè¥¿äº†" [positive]
3. "æ‹å–è¡Œå¤ªå·®åŠ²äº†" [negative]
4. "auction sucks" [negative]
5. "æ‹å–è¡Œæœ‰äººå‘åŒ…" [neutral]
</sentiment>

Skip the preamble, go straight into the answer.
'''
st.code(code, language='python')



st.markdown("ç¤ºä¾‹ä»£ç å¦‚ä¸‹ï¼š")
code = '''
url = domain_url + "/prompts"

headers = {
  'x-api-key': api_key,
  'Content-Type': 'application/json'
}
response = json.loads(requests.request("GET", url, headers=headers).text)

payload = json.dumps({
  "topic": topic,
  "prompt_rag": prompt_rag,
  "prompt_sentiment": prompt_sentiment
})
headers = {
  'x-api-key': api_key,
  'Content-Type': 'application/json'
}

response = requests.request("POST", url, headers=headers, data=payload)
'''
st.code(code, language='python')
